







![image-20210324114124670](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20210324114124670.png)  



## config

### config/default.py

+ TransPose

```
# Transformer
_C.MODEL.BOTTLENECK_NUM = 0
_C.MODEL.DIM_MODEL = 256
_C.MODEL.DIM_FEEDFORWARD = 512
_C.MODEL.ENCODER_LAYERS = 6
_C.MODEL.N_HEAD = 8
_C.MODEL.ATTENTION_ACTIVATION = 'relu'
_C.MODEL.POS_EMBEDDING = 'learnable'
_C.MODEL.INTERMEDIATE_SUP = False
_C.MODEL.PE_ONLY_AT_BEGIN = False
#### 

_C.TRAIN.LR_END = 0.00001

# darkpose
_C.TEST.BLUR_KERNEL = 3 

```

+ UDP

```
_C.CONTINUE_FROM_BEST =False
_C.MODEL_BEST =''

_C.LOSS.REDUCTION = 'mean'

_C.LOSS.KPD = 4.0
```



## core

### core/function.py

+ TransPose与DARK一致，UDP-TransPose直接根据UDP改

### core/inference.py

+ TransPose与DARK略有不同，但是我认为没啥区别：core/function.py中validate函数调用的时候并没有传transform_back这个参数，因此UDP-TransPose直接根据UDP改：

```
            preds, maxvals = get_final_preds(
                config, output.clone().cpu().numpy(), c, s)
```



```
# TransPose
def get_final_preds(config, hm, center, scale, transform_back=True):
    coords, maxvals = get_max_preds(hm)
    heatmap_height = hm.shape[2]
    heatmap_width = hm.shape[3]

    # post-processing
    hm = gaussian_blur(hm, config.TEST.BLUR_KERNEL)
    hm = np.maximum(hm, 1e-10)
    hm = np.log(hm)
    for n in range(coords.shape[0]):
        for p in range(coords.shape[1]):
            coords[n,p] = taylor(hm[n][p], coords[n][p])

    preds = coords.copy()

    if transform_back:
        # Transform back
        for i in range(coords.shape[0]):
            preds[i] = transform_preds(
                coords[i], center[i], scale[i], [heatmap_width, heatmap_height]
            )

    return preds, maxvals
```



```
# DarkPose
def get_final_preds(config, hm, center, scale):
    coords, maxvals = get_max_preds(hm)
    heatmap_height = hm.shape[2]
    heatmap_width = hm.shape[3]

    # post-processing
    hm = gaussian_blur(hm, config.TEST.BLUR_KERNEL)
    hm = np.maximum(hm, 1e-10)
    hm = np.log(hm)
    for n in range(coords.shape[0]):
        for p in range(coords.shape[1]):
            coords[n,p] = taylor(hm[n][p], coords[n][p])

    preds = coords.copy()

    # Transform back
    for i in range(coords.shape[0]):
        preds[i] = transform_preds(
            coords[i], center[i], scale[i], [heatmap_width, heatmap_height]
        )

    return preds, maxvals
```



### core/loss.py

+ TransPose与DARK一致，UDP-TransPose直接根据UDP改





## models

+ 注意根据UDP进行修改，特别是**神经网络输出heatmap的地方**；

```
        if not cfg.MODEL.TARGET_TYPE=='offset':
            factor=1
        else:
            factor=3
        self.final_layer = nn.Conv2d(
            in_channels=pre_stage_channels[0],
            out_channels=cfg.MODEL.NUM_JOINTS*factor,
            kernel_size=extra.FINAL_CONV_KERNEL,
            stride=1,
            padding=1 if extra.FINAL_CONV_KERNEL == 3 else 0
        )
```



### models/transpose_h.py





## dataset

### dataset/coco.py

+ TransPose，这里与DarkPose一致

```
obj['clean_bbox'] = [x1, y1, x2-x1+1, y2-y1+1]

center[0] = x + (w - 1) * 0.5
center[1] = y + (h - 1) * 0.5
```

+ UDP，这里与HRNet一致

```
obj['clean_bbox'] = [x1, y1, x2-x1, y2-y1]

center[0] = x + w * 0.5
center[1] = y + h * 0.5
```



### dataset/JointsDataset.py

+ TransPose

```
        w = right_bottom[0] - left_top[0] + 1
        h = right_bottom[1] - left_top[1] + 1
        
        joints_heatmap = joints.copy()
        trans = get_affine_transform(c, s, r, self.image_size)
        trans_heatmap = get_affine_transform(c, s, r, self.heatmap_size)

        input = cv2.warpAffine(
            data_numpy,
            trans,
            (int(self.image_size[0]), int(self.image_size[1])),
            flags=cv2.INTER_LINEAR)

        for i in range(self.num_joints):
            if joints_vis[i, 0] > 0.0:
                joints[i, 0:2] = affine_transform(joints[i, 0:2], trans)
                joints_heatmap[i, 0:2] = affine_transform(joints_heatmap[i, 0:2], trans_heatmap)

        target, target_weight = self.generate_target(joints_heatmap, joints_vis)
        
    def generate_target(self, joints, joints_vis):
        '''
        :param joints:  [num_joints, 3]
        :param joints_vis: [num_joints, 3]
        :return: target, target_weight(1: visible, 0: invisible)
        '''
        target_weight = np.ones((self.num_joints, 1), dtype=np.float32)
        target_weight[:, 0] = joints_vis[:, 0]


        if self.target_type == 'gaussian':
            target = np.zeros((self.num_joints,
                               self.heatmap_size[1],
                               self.heatmap_size[0]),
                              dtype=np.float32)

            tmp_size = self.sigma * 3

            for joint_id in range(self.num_joints):
                target_weight[joint_id] = \
                    self.adjust_target_weight(joints[joint_id], target_weight[joint_id], tmp_size)
                
                if target_weight[joint_id] == 0:
                    continue

                mu_x = joints[joint_id][0]
                mu_y = joints[joint_id][1]
                
                x = np.arange(0, self.heatmap_size[0], 1, np.float32)
                y = np.arange(0, self.heatmap_size[1], 1, np.float32)
                y = y[:, np.newaxis]

                v = target_weight[joint_id]
                if v > 0.5:
                    target[joint_id] = np.exp(- ((x - mu_x) ** 2 + (y - mu_y) ** 2) / (2 * self.sigma ** 2))

        if self.use_different_joints_weight:
            target_weight = np.multiply(target_weight, self.joints_weight)

        return target, target_weight


    def adjust_target_weight(self, joint, target_weight, tmp_size):
        # feat_stride = self.image_size / self.heatmap_size
        mu_x = joint[0]
        mu_y = joint[1]
        # Check that any part of the gaussian is in-bounds
        ul = [int(mu_x - tmp_size), int(mu_y - tmp_size)]
        br = [int(mu_x + tmp_size + 1), int(mu_y + tmp_size + 1)]
        if ul[0] >= self.heatmap_size[0] or ul[1] >= self.heatmap_size[1] \
                or br[0] < 0 or br[1] < 0:
            # If not, just return the image as is
            target_weight = 0

        return target_weight

```

+ UDP

```
import math

def get_warpmatrix(theta,size_input,size_dst,size_target):
    '''

    :param theta: angle
    :param size_input:[w,h]
    :param size_dst: [w,h]
    :param size_target: [w,h]/200.0
    :return:
    '''
    size_target = size_target * 200.0
    theta = theta / 180.0 * math.pi
    matrix = np.zeros((2,3),dtype=np.float32)
    scale_x = size_target[0]/size_dst[0]
    scale_y = size_target[1]/size_dst[1]
    matrix[0, 0] = math.cos(theta) * scale_x
    matrix[0, 1] = math.sin(theta) * scale_y
    matrix[0, 2] = -0.5 * size_target[0] * math.cos(theta) - 0.5 * size_target[1] * math.sin(theta) + 0.5 * size_input[0]
    matrix[1, 0] = -math.sin(theta) * scale_x
    matrix[1, 1] = math.cos(theta) * scale_y
    matrix[1, 2] = 0.5*size_target[0]*math.sin(theta)-0.5*size_target[1]*math.cos(theta)+0.5*size_input[1]
    return matrix

def rotate_points(src_points, angle,c, dst_img_shape,size_target, do_clip=True):
    # src_points: (num_points, 2)
    # img_shape: [h, w, c]
    size_target = size_target * 200.0
    src_img_center = c
    scale_x = (dst_img_shape[0]-1.0)/size_target[0]
    scale_y = (dst_img_shape[1]-1.0)/size_target[1]
    radian = angle / 180.0 * math.pi
    radian_sin = -math.sin(radian)
    radian_cos = math.cos(radian)
    dst_points = np.zeros(src_points.shape, dtype=src_points.dtype)
    src_x = src_points[:, 0] - src_img_center[0]
    src_y = src_points[:, 1] - src_img_center[1]
    dst_points[:, 0] = radian_cos * src_x + radian_sin * src_y
    dst_points[:, 1] = -radian_sin * src_x + radian_cos * src_y
    dst_points[:, 0] += size_target[0]*0.5
    dst_points[:, 1] += size_target[1]*0.5
    dst_points[:, 0] *= scale_x
    dst_points[:, 1] *= scale_y
    if do_clip:
        dst_points[:, 0] = np.clip(dst_points[:, 0], 0, dst_img_shape[1] - 1)
        dst_points[:, 1] = np.clip(dst_points[:, 1], 0, dst_img_shape[0] - 1)
    return dst_points
    
self.kpd = cfg.LOSS.KPD

        w = right_bottom[0] - left_top[0]
        h = right_bottom[1] - left_top[1]
        
        trans = get_warpmatrix(r,c*2.0,self.image_size-1.0,s)
        input = cv2.warpAffine(data_numpy, trans, (int(self.image_size[0]), int(self.image_size[1])), flags=cv2.WARP_INVERSE_MAP|cv2.INTER_LINEAR)
        joints[:, 0:2] = rotate_points(joints[:, 0:2], r, c, self.image_size, s, False)
        
        target, target_weight = self.generate_target(joints, joints_vis)
        
    def generate_target(self, joints, joints_vis):
        '''
        :param joints:  [num_joints, 3]
        :param joints_vis: [num_joints, 3]
        :return: target, target_weight(1: visible, 0: invisible)
        '''
        target_weight = np.ones((self.num_joints, 1), dtype=np.float32)
        target_weight[:, 0] = joints_vis[:, 0]


        if self.target_type == 'gaussian':
            target = np.zeros((self.num_joints,
                               self.heatmap_size[1],
                               self.heatmap_size[0]),
                              dtype=np.float32)

            tmp_size = self.sigma * 3

            for joint_id in range(self.num_joints):
                #Todo
                feat_stride = (self.image_size-1.0) / (self.heatmap_size-1.0)
                # feat_stride = self.image_size / self.heatmap_size
                mu_x = int(joints[joint_id][0] / feat_stride[0] + 0.5)
                mu_y = int(joints[joint_id][1] / feat_stride[1] + 0.5)
                # Check that any part of the gaussian is in-bounds
                ul = [int(mu_x - tmp_size), int(mu_y - tmp_size)]
                br = [int(mu_x + tmp_size + 1), int(mu_y + tmp_size + 1)]
                if ul[0] >= self.heatmap_size[0] or ul[1] >= self.heatmap_size[1] \
                        or br[0] < 0 or br[1] < 0:
                    # If not, just return the image as is
                    target_weight[joint_id] = 0
                    continue

                # # Generate gaussian
                size = 2 * tmp_size + 1
                x = np.arange(0, size, 1, np.float32)
                y = x[:, np.newaxis]
                x0 = y0 = size // 2
                #Todo
                mu_x_ac = joints[joint_id][0] / feat_stride[0]
                mu_y_ac = joints[joint_id][1] / feat_stride[1]
                x0 = y0 = size // 2
                x0 += mu_x_ac-mu_x
                y0 += mu_y_ac-mu_y
                # The gaussian is not normalized, we want the center value to equal 1
                g = np.exp(- ((x - x0) ** 2 + (y - y0) ** 2) / (2 * self.sigma ** 2))

                # Usable gaussian range
                g_x = max(0, -ul[0]), min(br[0], self.heatmap_size[0]) - ul[0]
                g_y = max(0, -ul[1]), min(br[1], self.heatmap_size[1]) - ul[1]
                # Image range
                img_x = max(0, ul[0]), min(br[0], self.heatmap_size[0])
                img_y = max(0, ul[1]), min(br[1], self.heatmap_size[1])

                v = target_weight[joint_id]
                if v > 0.5:
                    target[joint_id][img_y[0]:img_y[1], img_x[0]:img_x[1]] = \
                        g[g_y[0]:g_y[1], g_x[0]:g_x[1]]
        elif self.target_type == 'offset':
            # self.heatmap_size: [48,64] [w,h]
            target = np.zeros((self.num_joints,
                               3,
                               self.heatmap_size[1]*
                               self.heatmap_size[0]),
                              dtype=np.float32)
            feat_width = self.heatmap_size[0]
            feat_height = self.heatmap_size[1]
            feat_x_int = np.arange(0, feat_width)
            feat_y_int = np.arange(0, feat_height)
            feat_x_int, feat_y_int = np.meshgrid(feat_x_int, feat_y_int)
            feat_x_int = feat_x_int.reshape((-1,))
            feat_y_int = feat_y_int.reshape((-1,))
            kps_pos_distance_x = self.kpd
            kps_pos_distance_y = self.kpd
            feat_stride = (self.image_size - 1.0) / (self.heatmap_size - 1.0)
            for joint_id in range(self.num_joints):
                mu_x = joints[joint_id][0] / feat_stride[0]
                mu_y = joints[joint_id][1] / feat_stride[1]
                # Check that any part of the gaussian is in-bounds

                x_offset = (mu_x - feat_x_int) / kps_pos_distance_x
                y_offset = (mu_y - feat_y_int) / kps_pos_distance_y

                dis = x_offset ** 2 + y_offset ** 2
                keep_pos = np.where((dis <= 1) & (dis >= 0))[0]
                v = target_weight[joint_id]
                if v > 0.5:
                    target[joint_id, 0, keep_pos] = 1
                    target[joint_id, 1, keep_pos] = x_offset[keep_pos]
                    target[joint_id, 2, keep_pos] = y_offset[keep_pos]
            target=target.reshape((self.num_joints*3,self.heatmap_size[1],self.heatmap_size[0]))
        if self.use_different_joints_weight:
            target_weight = np.multiply(target_weight, self.joints_weight)

        return target, target_weight
```



## utils

### utils/transforms.py

+ TransPose与DARK一致，UDP-TransPose直接根据UDP改；

### utils/utils.py

+ TransPose与DarkPose略有不同，而DarkPose与UDP完全一致，因此UDP-TransPose与TransPose保持一致，不修改：

```
# TransPose
            summary.append(
                ModuleDetails(
                    name=layer_name,
                    input_size=list(input[0].size()),
                    output_size=[0,0],#list(output.size()),
                    num_parameters=params,
                    multiply_adds=flops)
            )
```



```
# DarkPose
            summary.append(
                ModuleDetails(
                    name=layer_name,
                    input_size=list(input[0].size()),
                    output_size=list(output.size()),
                    num_parameters=params,
                    multiply_adds=flops)
            )
```



### utils/vis.py

+ UDP-TransPose直接根据UDP改掉下面这段代码：

```
    cv2.imwrite(file_name, cv2.cvtColor(ndarr,cv2.COLOR_RGB2BGR))
```



+ TransPose比DarkPose多了下面这段代码，UDP-TransPose保留

```
# coco_keypoints_id['nose'] = 0
# coco_keypoints_id['l_eye']= 1
# coco_keypoints_id['r_eye'] = 2
# coco_keypoints_id['l_ear'] = 3
# coco_keypoints_id['r_ear'] = 4
# coco_keypoints_id['l_shoulder'] = 5
# coco_keypoints_id['r_shoulder'] = 6
# coco_keypoints_id['l_elbow'] = 7
# coco_keypoints_id['r_elbow'] = 8
# coco_keypoints_id['l_wrist'] = 9
# coco_keypoints_id['r_wrist'] = 10
# coco_keypoints_id['l_hip'] =11
# coco_keypoints_id['r_hip'] = 12
# coco_keypoints_id['l_knee'] = 13
# coco_keypoints_id['r_knee'] = 14
# coco_keypoints_id['l_ankle'] = 15
# coco_keypoints_id['r_ankle'] = 16


class plt_config:
    def __init__(self, dataset_name):
        if dataset_name == 'coco':
            self.n_kpt = 17
            # edge , color
            self.EDGES = [([15, 13], [255, 0, 0]),  # l_ankle -> l_knee
                          ([13, 11], [155, 85, 0]),  # l_knee -> l_hip
                          ([11, 5],  [155, 85, 0]),  # l_hip -> l_shoulder
                          ([12, 14], [0, 0, 255]),  # r_hip -> r_knee
                          ([14, 16], [17, 25, 10]),  # r_knee -> r_ankle
                          ([12, 6],  [0, 0, 255]),  # r_hip  -> r_shoulder
                          ([3, 1],   [0, 255, 0]),  # l_ear -> l_eye
                          ([1, 2],   [0, 255, 5]),  # l_eye -> r_eye
                          ([1, 0],   [0, 255, 170]),  # l_eye -> nose
                          ([0, 2],   [0, 255, 25]),  # nose -> r_eye
                          ([2, 4],   [0, 17, 255]),  # r_eye -> r_ear
                          ([9, 7],   [0, 220, 0]),  # l_wrist -> l_elbow
                          ([7, 5],   [0, 220, 0]),  # l_elbow -> l_shoulder
                          ([5, 6],   [125, 125, 155]), # l_shoulder -> r_shoulder
                          ([6, 8],   [25, 0, 55]),  # r_shoulder -> r_elbow
                          ([8, 10], [25, 0, 255])]  # r_elbow -> r_wrist
        elif dataset_name == 'jta':
            self.n_kpt = 22
            self.EDGES = [
                (0, 1),  # head_top -> head_center
                (1, 2),  # head_center -> neck
                (2, 3),  # neck -> right_clavicle
                (3, 4),  # right_clavicle -> right_shoulder
                (4, 5),  # right_shoulder -> right_elbow
                (5, 6),  # right_elbow -> right_wrist
                (2, 7),  # neck -> left_clavicle
                (7, 8),  # left_clavicle -> left_shoulder
                (8, 9),  # left_shoulder -> left_elbow
                (9, 10),  # left_elbow -> left_wrist
                (2, 11),  # neck -> spine0
                (11, 12),  # spine0 -> spine1
                (12, 13),  # spine1 -> spine2
                (13, 14),  # spine2 -> spine3
                (14, 15),  # spine3 -> spine4
                (15, 16),  # spine4 -> right_hip
                (16, 17),  # right_hip -> right_knee
                (17, 18),  # right_knee -> right_ankle
                (15, 19),  # spine4 -> left_hip
                (19, 20),  # left_hip -> left_knee
                (20, 21)  # left_knee -> left_ankle
            ]
        else:
            raise ValueError(
                "{} dataset is not supported".format(dataset_name))


def plot_poses(img, skeletons, config=plt_config('coco'), save_path=None, dataset_name='coco'):
    # std = torch.tensor([0.229, 0.224, 0.225]).unsqueeze(-1).unsqueeze(-1)
    # mean = torch.tensor([0.485, 0.456, 0.406]).unsqueeze(-1).unsqueeze(-1)
    # # input = input.detach().cpu()
    # #if dataset_name == 'coco':
    # img = img * std + mean
    # img = img.permute(1, 2, 0).detach().numpy()  # [H,W,3]
    # colors = [[255, 0, 0],
    #           [155, 85, 0],
    #           [255, 170, 0],
    #           [255, 55, 0],
    #           [17, 25, 10],
    #           [85, 55, 0],
    #           [0, 255, 0],
    #           [0, 255, 5],
    #           [0, 255, 170],
    #           [0, 255, 25],
    #           [0, 17, 255],
    #           [0, 185, 255],
    #           [0, 0, 255],
    #           [125, 0, 255],
    #           [170, 0, 25],
    #           [25, 0, 255],
    #           [255, 0, 170],
    #           [255, 0, 85],
    #           [0, 170, 255],
    #           [0, 85, 255],
    #           [0, 0, 255],
    #           [85, 0, 255],
    #           [70, 0, 255],
    #           [25, 0, 255],
    #           [255, 0, 70],
    #           [55, 10, 5]]

    cmap = matplotlib.cm.get_cmap('hsv')
    canvas = img.copy()
    n_kpt = config.n_kpt
    for i in range(n_kpt):
        rgba = np.array(cmap(1 - i / n_kpt - 1. / n_kpt * 2))
        rgba[0:3] *= 255
        for j in range(len(skeletons)):
            if len(skeletons[j][i]) > 2 and skeletons[j][i, 2] > 0:
                cv2.circle(canvas, tuple(skeletons[j][i, 0:2].astype(
                    'int32')), 3, (255,255,255), thickness=-1)

    # to_plot = cv2.addWeighted(img, 0.3, canvas, 0.7, 0)
    stickwidth = 2

    for i in range(len(config.EDGES)):
        for j in range(len(skeletons)):
            edge = config.EDGES[i][0]
            color = config.EDGES[i][1]
            if len(skeletons[j][edge[0]]) > 2:
                if skeletons[j][edge[0], 2] == 0 or skeletons[j][edge[1], 2] == 0:
                    continue

            cur_canvas = canvas.copy()
            X = [skeletons[j][edge[0], 1], skeletons[j][edge[1], 1]]
            Y = [skeletons[j][edge[0], 0], skeletons[j][edge[1], 0]]
            mX = np.mean(X)
            mY = np.mean(Y)
            length = ((X[0] - X[1]) ** 2 + (Y[0] - Y[1]) ** 2) ** 0.5
            angle = math.degrees(math.atan2(X[0] - X[1], Y[0] - Y[1]))
            polygon = cv2.ellipse2Poly((int(mY), int(mX)), (int(
                length / 2), stickwidth), int(angle), 0, 360, 1)
            cv2.fillConvexPoly(cur_canvas, polygon, color)
            canvas = cv2.addWeighted(canvas, 0.4, cur_canvas, 0.6, 0)

    return canvas

```



## experiments/coco/transpose_h/TP_H_w32_256x192_stage3_1_4_d64_h128_relu_enc4_mh1.yaml

```
TARGET_TYPE: 'offset' # gaussian
```





## tools/train.py、tools/test.py

+ 根据UDP进行了简单修改

